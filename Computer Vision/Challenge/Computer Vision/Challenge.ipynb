{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44df9ba",
   "metadata": {},
   "source": [
    "CHALLENGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3d4bb",
   "metadata": {},
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b8172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import uuid\n",
    "import os\n",
    "import time\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9789ad",
   "metadata": {},
   "source": [
    "Label Collection Images Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e24d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Cars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba22e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_path = os.path.join(\"data\",\"images\")\n",
    "if not os.path.exists(Images_path):\n",
    "    os.mkdir(Images_path)\n",
    "\n",
    "for label in labels:\n",
    "    path = os.path.join(Images_path,label)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf26ccd",
   "metadata": {},
   "source": [
    "Capture Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d2b930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for Cars\n",
      "Collecting images for 20\n",
      "Collecting images for 40\n",
      "Collecting images for 60\n",
      "Collecting images for 80\n",
      "Collecting images for 100\n",
      "Collecting images for 120\n",
      "Collecting images for 140\n",
      "Collecting images for 160\n",
      "Collecting images for 180\n",
      "Collecting images for 200\n",
      "Collecting images for 220\n",
      "Collecting images for 240\n",
      "Collecting images for 260\n",
      "Collecting images for 280\n",
      "Collecting images for 300\n",
      "Collecting images for 320\n",
      "Collecting images for 340\n",
      "Collecting images for 360\n",
      "Collecting images for 380\n",
      "Collecting images for 400\n",
      "Collecting images for 420\n",
      "Collecting images for 440\n",
      "Collecting images for 460\n",
      "Collecting images for 480\n",
      "Collecting images for 500\n",
      "Collecting images for 520\n",
      "Collecting images for 540\n",
      "Collecting images for 560\n",
      "Collecting images for 580\n",
      "Collecting images for 600\n",
      "Collecting images for 620\n",
      "Collecting images for 640\n",
      "Collecting images for 660\n",
      "Collecting images for 680\n",
      "Collecting images for 700\n",
      "Collecting images for 720\n",
      "Collecting images for 740\n",
      "Collecting images for 760\n",
      "Collecting images for 780\n",
      "Collecting images for 800\n",
      "Collecting images for 820\n",
      "Collecting images for 840\n",
      "Collecting images for 860\n",
      "Collecting images for 880\n",
      "Collecting images for 900\n",
      "Collecting images for 920\n",
      "Collecting images for 940\n",
      "Collecting images for 960\n",
      "Collecting images for 980\n",
      "Collecting images for 1000\n",
      "Collecting images for 1020\n",
      "Collecting images for 1040\n",
      "Collecting images for 1060\n",
      "Collecting images for 1080\n",
      "Collecting images for 1100\n",
      "Collecting images for 1120\n",
      "Collecting images for 1140\n",
      "Collecting images for 1160\n",
      "Collecting images for 1180\n",
      "Collecting images for 1200\n",
      "Collecting images for 1220\n",
      "Collecting images for 1240\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    capture = cv2.VideoCapture(\"video_01.mp4\")\n",
    "    framerate = capture.get(60)\n",
    "    print(\"Collecting images for {}\".format(label))\n",
    "    counter =1\n",
    "    time.sleep(3)\n",
    "    while capture.isOpened():\n",
    "        \n",
    "        sucess,frame = capture.read()\n",
    "        if counter%20==0: # every 20 frames\n",
    "            print(\"Collecting images for {}\".format(counter))\n",
    "            img_name = os.path.join(Images_path,label,label+\".\"+\"{}.jpg\".format(str(uuid.uuid1())))\n",
    "            cv2.imwrite(img_name,frame)\n",
    "            # cv2.imshow('frame', frame)\n",
    "    \n",
    "\n",
    "        if sucess == False:\n",
    "            break\n",
    "        counter+=1    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846fe913",
   "metadata": {},
   "source": [
    "Image Labelling\n",
    "Labelling done using LabelIMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7557140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELLING_PATH = os.path.join(\"data\",\"labelling\")\n",
    "# if not os.path.exists(LABELLING_PATH):\n",
    "#     os.mkdir(LABELLING_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db6832",
   "metadata": {},
   "source": [
    "TESTING AND TRAINING SET SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc45b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join(\"data\",\"Train\")\n",
    "TEST_PATH= os.path.join(\"data\",\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eed4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "\n",
    "\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('model', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('model', 'scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('model', 'models'),\n",
    "    'ANNOTATION_PATH': os.path.join('model', 'workspace', 'annotations'),\n",
    "    'IMAGE_PATH': os.path.join('model', 'workspace', 'images'),\n",
    "    'MODEL_PATH': os.path.join('model', 'workspace', 'models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('model', 'workspace', 'pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('model', 'workspace', 'models', CUSTOM_MODEL_NAME),\n",
    "    'OUTPUT_PATH': os.path.join('model', 'workspace', 'models', CUSTOM_MODEL_NAME, 'export'),\n",
    "    'TFJS_PATH': os.path.join('model', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
    "    'TFLITE_PATH': os.path.join('model', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
    "    'PROTOC_PATH': os.path.join('model', 'protoc')\n",
    "}\n",
    "\n",
    "files = {\n",
    "    'PIPELINE_CONFIG': os.path.join('model', 'workspace', 'models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}\n",
    "\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a363283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/tensorflow/models/tree/master/research/object_detection\n",
    "#  model :tf2_detection_zoo\n",
    "# model : SSD MobileNet V2 FPNLite 320x320\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac301418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-13 23:37:58--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.167.112, 2404:6800:4006:80b::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.167.112|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20515344 (20M) [application/x-tar]\n",
      "Saving to: 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  4.71MB/s    in 5.3s    \n",
      "\n",
      "2021-11-13 23:38:04 (3.69 MB/s) - 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
      "\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca5a31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'Cars', 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc18babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86b3a98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: model/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: model/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832a93d",
   "metadata": {},
   "source": [
    "Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05fd7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c8103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b38b605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d16251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a51b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(\n",
    "    paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [\n",
    "    os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [\n",
    "    os.path.join(paths['ANNOTATION_PATH'], 'test.record')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b254dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
    "    f.write(config_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b83c01",
   "metadata": {},
   "source": [
    "TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dda92afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(\n",
    "    paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38dd1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(\n",
    "    TRAINING_SCRIPT, paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc36ea22",
   "metadata": {},
   "source": [
    "from this directory RUN\n",
    "python ~/git/Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=model/workspace/models/my_ssd_mobnet --pipeline_config_path=model/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0849181",
   "metadata": {},
   "source": [
    "EVALUATE MODEL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6414153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(\n",
    "    TRAINING_SCRIPT, paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5823e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python model/models/research/object_detection/model_main_tf2.py --model_dir=model/workspace/models/my_ssd_mobnet --pipeline_config_path=model/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=model/workspace/models/my_ssd_mobnet\n"
     ]
    }
   ],
   "source": [
    "print(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115185c",
   "metadata": {},
   "source": [
    "python ~/git/Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=model/workspace/models/my_ssd_mobnet --pipeline_config_path=model/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=model/workspace/models/my_ssd_mobnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e653e3f",
   "metadata": {},
   "source": [
    "LOAD MODEL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a49d4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "561b3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "category_index = label_map_util.create_category_index_from_labelmap(\n",
    "    files['LABELMAP'])\n",
    "IMAGE_PATH = os.path.join(\n",
    "    paths['IMAGE_PATH'], 'test', 'Cars.229d0109-4450-11ec-b499-0433c2f55c1c.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "392dc15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/workspace/images/test/Cars.229d0109-4450-11ec-b499-0433c2f55c1c.jpg'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaba7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71f07257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-122abce74a30>:32: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(\n",
    "    np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(\n",
    "    np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections,\n",
    "    detections['detection_boxes'],\n",
    "    detections['detection_classes']+label_id_offset,\n",
    "    detections['detection_scores'],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=5,\n",
    "    min_score_thresh=.8,\n",
    "    agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "plt.savefig(\"Test.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156acfd",
   "metadata": {},
   "source": [
    "SEEING IT FROM THE VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00e21bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"video_01.mp4\")\n",
    "framerate = capture.get(60)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(\n",
    "        np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(\n",
    "        np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes']+label_id_offset,\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=5,\n",
    "        min_score_thresh=.8,\n",
    "        agnostic_mode=False)\n",
    "\n",
    "    # cv2.imshow('object detection',  cv2.resize(\n",
    "    #     image_np_with_detections, (800, 600)))\n",
    "\n",
    "    cv2.imshow('object detection',  \n",
    "        image_np_with_detections)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e1362",
   "metadata": {},
   "source": [
    "FREEZE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2969a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FREEZE_SCRIPT = os.path.join(\n",
    "    paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3a19408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python model/models/research/object_detection/exporter_main_v2.py  --input_type=image_tensor --pipeline_config_path=model/workspace/models/my_ssd_mobnet/pipeline.config --trained_checkpoint_dir=model/workspace/models/my_ssd_mobnet --output_directory=model/workspace/models/my_ssd_mobnet/export\n"
     ]
    }
   ],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(\n",
    "    FREEZE_SCRIPT, files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])\n",
    "\n",
    "\n",
    "print(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f50068a",
   "metadata": {},
   "source": [
    "python ~/git/Tensorflow/models/research/object_detection/exporter_main_v2.py  --input_type=image_tensor --pipeline_config_path=model/workspace/models/my_ssd_mobnet/pipeline.config --trained_checkpoint_dir=model/workspace/models/my_ssd_mobnet --output_directory=model/workspace/models/my_ssd_mobnet/export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9163215",
   "metadata": {},
   "source": [
    "USE FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "679ff3ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'/home/esteban/git/Deep_Learning_varied/Computer Vision/Challenge/Computer Vision/model/workspace/models/my_ssd_mobnet/export/pipeline.config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-28de3ce6ce52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load pipeline config and build a detection model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m configs = config_util.get_configs_from_pipeline_file(\n\u001b[0;32m---> 11\u001b[0;31m     files['/home/esteban/git/Deep_Learning_varied/Computer Vision/Challenge/Computer Vision/model/workspace/models/my_ssd_mobnet/export/pipeline.config'])\n\u001b[0m\u001b[1;32m     12\u001b[0m detection_model = model_builder.build(\n\u001b[1;32m     13\u001b[0m     model_config=configs['model'], is_training=False)\n",
      "\u001b[0;31mKeyError\u001b[0m: '/home/esteban/git/Deep_Learning_varied/Computer Vision/Challenge/Computer Vision/model/workspace/models/my_ssd_mobnet/export/pipeline.config'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(\n",
    "    model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda6e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
