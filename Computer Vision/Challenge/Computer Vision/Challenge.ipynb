{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44df9ba",
   "metadata": {},
   "source": [
    "## CHALLENGE\n",
    "# Esteban Andrade\n",
    "\n",
    "The Generates Proposal consist to using an object detection with the intent to detect only vehicles at first. \n",
    "For this I have decided to use a model such as SSD MobileNet V2 FPNLite 320x320\n",
    "This is a lite feature extractor that uses training images scaled to 320x320.\n",
    "The benefit of this is that it will provide an adequete speed during execution. \n",
    "However for better accuracy we could choose a much more robust model , however the speed could be penalised. \n",
    "For this only 23 images were used for training and it will run over 2000 epochs. \n",
    "This could help to provide an insight on how the model could work and whether its a viable solution. \n",
    "As it is an adequte model improvement could be done such as adding more images, better labeling, and increasing the number of epochs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3d4bb",
   "metadata": {},
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import uuid\n",
    "import os\n",
    "import time\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9789ad",
   "metadata": {},
   "source": [
    "## Label Collection Images Collection.\n",
    "In This Step We number of Labels we will use for Training. Then we Check Create The subsequent Subforlders to add the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e24d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Cars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba22e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_path = os.path.join(\"data\",\"images\")\n",
    "if not os.path.exists(Images_path):\n",
    "    os.mkdir(Images_path)\n",
    "\n",
    "for label in labels:\n",
    "    path = os.path.join(Images_path,label)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf26ccd",
   "metadata": {},
   "source": [
    "## Capture Images\n",
    "In this Step we store the images every 20 frames and we will use them for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    capture = cv2.VideoCapture(\"video_01.mp4\")\n",
    "    framerate = capture.get(60)\n",
    "    print(\"Collecting images for {}\".format(label))\n",
    "    counter =1\n",
    "    time.sleep(3)\n",
    "    while capture.isOpened():\n",
    "        \n",
    "        sucess,frame = capture.read()\n",
    "        if counter%20==0: # every 20 frames\n",
    "            print(\"Collecting images for {}\".format(counter))\n",
    "            img_name = os.path.join(Images_path,label,label+\".\"+\"{}.jpg\".format(str(uuid.uuid1())))\n",
    "            #cv2.imwrite(img_name,frame)\n",
    "            cv2.imshow('frame', frame)\n",
    "    \n",
    "\n",
    "        if sucess == False:\n",
    "            break\n",
    "        counter+=1    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846fe913",
   "metadata": {},
   "source": [
    "## Image Labelling\n",
    "Labelling done using LabelIMG https://github.com/tzutalin/labelImg.\n",
    "We will Label all Data from the images and then we will move the data into Train and Testing Set accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db6832",
   "metadata": {},
   "source": [
    "## TESTING AND TRAINING SET SPLIT and SETTING PATHS.\n",
    "\n",
    "This will create all the directories needed where all components will be downloaded.\n",
    "The model used will be \n",
    "# https://github.com/tensorflow/models/tree/master/research/object_detection\n",
    "# g3doc-->tf2_detection_zoo\n",
    "#  model : SSD MobileNet V2 FPNLite 320x320\n",
    "\n",
    "We choose this model as it provides us with a decent speed 19 ms and a mAP of 20.2 which is resonable for this dataset.\n",
    "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc45b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join(\"data\",\"Train\")\n",
    "TEST_PATH= os.path.join(\"data\",\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "\n",
    "\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('model', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('model', 'scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('model', 'models'),\n",
    "    'ANNOTATION_PATH': os.path.join('model', 'workspace', 'annotations'),\n",
    "    'IMAGE_PATH': os.path.join('model', 'workspace', 'images'),\n",
    "    'MODEL_PATH': os.path.join('model', 'workspace', 'models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('model', 'workspace', 'pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('model', 'workspace', 'models', CUSTOM_MODEL_NAME),\n",
    "    'OUTPUT_PATH': os.path.join('model', 'workspace', 'models', CUSTOM_MODEL_NAME, 'export'),\n",
    "    'TFJS_PATH': os.path.join('model', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
    "    'TFLITE_PATH': os.path.join('model', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
    "    'PROTOC_PATH': os.path.join('model', 'protoc')\n",
    "}\n",
    "\n",
    "files = {\n",
    "    'PIPELINE_CONFIG': os.path.join('model', 'workspace', 'models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}\n",
    "\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a363283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed84b0",
   "metadata": {},
   "source": [
    "# DOWNLOAD PRETRAINED MODEL AND MOVE IT TO LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac301418",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e4f4f1",
   "metadata": {},
   "source": [
    "# GENERATE LABEL MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'Cars', 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30899b5",
   "metadata": {},
   "source": [
    "# GENARATE TF RECORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832a93d",
   "metadata": {},
   "source": [
    "# Copy Model Config to Training Folder.\n",
    "\n",
    "The reason for this is to leave the config file as referance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8b764",
   "metadata": {},
   "source": [
    "# DEPENDENCIES\n",
    "\n",
    "Ensure to have Tensorflow installed as well as the object detection module from TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2c898",
   "metadata": {},
   "source": [
    "# UPDATE CONFIG FILE FOR NEW MODEL AND TRANSFER PARAMS\n",
    "We will adjust the pipeline config to suit our path and labels accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d16251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a51b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(\n",
    "    paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [\n",
    "    os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [\n",
    "    os.path.join(paths['ANNOTATION_PATH'], 'test.record')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
    "    f.write(config_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b83c01",
   "metadata": {},
   "source": [
    "# TRAIN MODEL.\n",
    "This will be used to train our model.\n",
    "We will use model_main_tf_2.py as the source for our training \n",
    "We will run this over 2000 epochs.\n",
    "https://github.com/tensorflow/models/tree/master/research/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda92afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(\n",
    "    paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(\n",
    "    TRAINING_SCRIPT, paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc36ea22",
   "metadata": {},
   "source": [
    "## from this directory RUN  in the terminal\n",
    "Ensure to have cloned the Tensorflow Object Detection models installed and set that path when running model_main_tf2.py.\n",
    "Ex. for my system is: \n",
    "\n",
    "python ~/git/Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=model/workspace/models/my_ssd_mobnet --pipeline_config_path=model/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0849181",
   "metadata": {},
   "source": [
    "## EVALUATE MODEL:\n",
    "We can use TensorBoard to evaluate our models and output of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(\n",
    "    TRAINING_SCRIPT, paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5823e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115185c",
   "metadata": {},
   "source": [
    "python ~/git/Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=model/workspace/models/my_ssd_mobnet --pipeline_config_path=model/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=model/workspace/models/my_ssd_mobnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e653e3f",
   "metadata": {},
   "source": [
    "## LOAD MODEL and Test \n",
    "We will load the output model which is under models \"model/workspace/models/my_ssd_mobnet\"\n",
    "and we will use the last check point for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e18af",
   "metadata": {},
   "source": [
    "# TEST WITH IMAGE FROM TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "category_index = label_map_util.create_category_index_from_labelmap(\n",
    "    files['LABELMAP'])\n",
    "IMAGE_PATH = os.path.join(\n",
    "    paths['IMAGE_PATH'], 'test', 'Cars.229d0109-4450-11ec-b499-0433c2f55c1c.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392dc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f07257",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(\n",
    "    np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(\n",
    "    np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections,\n",
    "    detections['detection_boxes'],\n",
    "    detections['detection_classes']+label_id_offset,\n",
    "    detections['detection_scores'],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=5,\n",
    "    min_score_thresh=.8,\n",
    "    agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "plt.savefig(\"Test.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156acfd",
   "metadata": {},
   "source": [
    "## Testing  FROM THE VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e21bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"video_01.mp4\")\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(\n",
    "        np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(\n",
    "        np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes']+label_id_offset,\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=5,\n",
    "        min_score_thresh=.8,\n",
    "        agnostic_mode=False)\n",
    "\n",
    "    # cv2.imshow('object detection',  cv2.resize(\n",
    "    #     image_np_with_detections, (800, 600)))\n",
    "\n",
    "    cv2.imshow('object detection',  \n",
    "        image_np_with_detections)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e1362",
   "metadata": {},
   "source": [
    "## FREEZE GRAPH\n",
    "We will freeze the graph in order to be used in other instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2969a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FREEZE_SCRIPT = os.path.join(\n",
    "    paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a19408",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(\n",
    "    FREEZE_SCRIPT, files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])\n",
    "\n",
    "\n",
    "print(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f50068a",
   "metadata": {},
   "source": [
    "python ~/git/Tensorflow/models/research/object_detection/exporter_main_v2.py  --input_type=image_tensor --pipeline_config_path=model/workspace/models/my_ssd_mobnet/pipeline.config --trained_checkpoint_dir=model/workspace/models/my_ssd_mobnet --output_directory=model/workspace/models/my_ssd_mobnet/export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9163215",
   "metadata": {},
   "source": [
    "## USE FINAL MODEL\n",
    "We will use the final model to test the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ff3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "\n",
    "\n",
    "FINAL_CONFIG = os.path.join(\n",
    "    'model', 'workspace', 'models', 'my_ssd_mobnet', 'export', 'pipeline.config')\n",
    "FINAL_CHECK_POINT = os.path.join(\n",
    "    'model', 'workspace', 'models', 'my_ssd_mobnet', 'export', 'checkpoint')\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(\n",
    "    FINAL_CONFIG)\n",
    "detection_model = model_builder.build(\n",
    "    model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(FINAL_CHECK_POINT, 'ckpt-0')).expect_partial()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"video_01.mp4\")\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    input_tensor = tf.convert_to_tensor(\n",
    "        image_np_expanded, dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(\n",
    "        np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes']+label_id_offset,\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=5,\n",
    "        min_score_thresh=.8,\n",
    "        agnostic_mode=False)\n",
    "\n",
    "    # cv2.imshow('object detection',  cv2.resize(\n",
    "    #     image_np_with_detections, (800, 600)))\n",
    "\n",
    "    cv2.imshow('object detection',\n",
    "               image_np_with_detections)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfadf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
